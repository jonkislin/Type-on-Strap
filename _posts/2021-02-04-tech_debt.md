---
published: true
---
## Avoiding Technical Debt  
A simple, opinionated list of advice for developers on data science projects.

### Code should control for a diversity of runtime and development environments

There are numerous ways to deal with this and all have tradeoffs.

- Code should control for a diversity of runtime and development environments
- Packages, programming language interpreter versions (python 3.6 vs 3.8 etc), operating systems, etc
- In python, make use of requirements.txt files at the least - conda can be nice but it's more complicated, and even just using requirements.txt and pip is easy.


### Code should be thoroughly version controlled

- Before you write any code, make sure you're working in an existing git repo or initialize a repo to start tracking work right away.
- There are benefits to keeping interoperable code in the same repository. Try not to proliferate too many repositories, and rather seek to keep your code organized and unused code pruned or explicitly kept in archive folders.
- On the other hand, a repository that's simply a dump of many unrelated codebases authored by users who never work with each other can also create headaches.
- Organization is key!
- Make sure you're familiar with git workflows. I'm partial to feature branch workflows and gitflow, and avoid forking workflows unless necessary.
- If you're unsure, look it up or ask! Git is one of those things that seems cumbersome at first but feels natural with time.
- Never push directly to `master`. :)


### Code should explain itself, and do so clearly

Any reasonably technical person should understand your code without needing a deep tutorial or lengthy documentation. 

- Clearer, longer variable names in underscore case like chesapeake_raster_raw are much preferrable to obscure shortened names like ChesRast_df1.
- Comments are mandatory. In some cases, comments should comprise up to 1/3 (or more) of the lines of code of a script.
- Vertical code organization within scripts is very important for readability (try not to exceed 70 characters per line, and never exceed 80 characters)
- If you notice you're copying and pasting any significant section of code, then you can probably make use of functions! (see next section)


### Code should be written in modular chunks making use of user-defined functions

You should never repeat code if you don't have to. Any code that repeats itself more than a couple times likely could have been written as a function.

I distinguish between two broad types of user-generated functions:

1. Script/module functions: every 'script' or 'pipeline step' should be a function definition that can be called by a runner/main script. The purpose here is to manage options/environments across functions such that the global namespace isn't littered with variables and we don't run into scoping problems)

2. Helper functions: functions that do a repeatable task across multiple scripts. The purpose here is to reduce code complexity and ease in development so that you only have to track one vesion of a repeatable task. The beauty is, if you have 10 very similar operations, instead of writing 10 separate functions, you can write one basic function (e.g maybe each of these operations involves logging into AWS temporarily, clearing out the local environment, and downloading 1-7 files locally. The function argument can simply dictate, via if/elses in the body of the function code, which files to download)

Use recommended conventional files like `namespace.py`, `main.py`, `__init__.py,` etc so that you only have to load modules (both user-created and pip-installed) once!

### Summary 

In short, what we are after is a codebase that might take a little longer to stand-up, but which will be considerably more bulletproof against technical debt!
